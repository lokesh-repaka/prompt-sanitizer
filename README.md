# LLM Guard Prompt Sanitizer

## Description

The **LLM Guard Prompt Sanitizer** is a powerful tool designed to automatically clean sensitive information from prompts, ensuring safe and secure interactions with Large Language Models (LLMs). This application leverages advanced input and output scanning techniques to identify and anonymize sensitive data, such as personal identifiers, contact information, and financial details, before they are processed by LLMs.

### Key Features

- **Sensitive Data Anonymization**: Automatically detects and removes sensitive information from user prompts.
- **User-Friendly Interface**: Built with Streamlit, providing an intuitive web interface for easy interaction.
- **Real-Time Feedback**: Users receive immediate validation of their prompts, including sanitized output and scores indicating the validity of the prompt.
- **Customizable Scanning**: Supports various input and output scanners to adapt to different use cases and requirements.

### Use Cases

- **Data Privacy**: Safeguard personal and sensitive information when using LLMs in applications.
- **Compliance**: Ensure compliance with data protection regulations by sanitizing prompts before processing.
- **Research and Development**: Facilitate safe experimentation with LLMs in academic and industrial research.

![Uploading image.pngâ€¦]()

